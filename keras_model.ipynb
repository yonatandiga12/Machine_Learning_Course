{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTjUvDHWFi_1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYn0UAYxFmAy",
        "outputId": "7ea56b37-9027-4696-ceb6-f70cd7b89fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading MNIST data...\n"
          ]
        }
      ],
      "source": [
        "# Load and Prepare Data (Same as before for fair comparison)\n",
        "print(\"Loading MNIST data...\")\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
        "\n",
        "X = ((X / 255.) - .5) * 2\n",
        "\n",
        "# Convert labels to integers\n",
        "y = y.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRpKygy3Fs6z"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=123, stratify=y\n",
        ")\n",
        "\n",
        "# One-hot encode labels for Keras training and AUC calculation\n",
        "enc = OneHotEncoder()\n",
        "y_train_onehot = enc.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
        "y_test_onehot = enc.transform(y_test.reshape(-1, 1)).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbndSav-FvXZ",
        "outputId": "edb371ac-7f05-43d7-82e4-96fb2d917b49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Hidden Layer 1\n",
        "    tf.keras.layers.Dense(500, activation='sigmoid', input_shape=(784,)),\n",
        "\n",
        "    # Hidden Layer 2\n",
        "    tf.keras.layers.Dense(500, activation='sigmoid'),\n",
        "\n",
        "    # Output Layer: 'softmax'\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8hD20w1F0HK"
      },
      "outputs": [],
      "source": [
        "# 4. Compile\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='mse',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq__5DpZF1lB",
        "outputId": "de07242c-8b3b-4e3e-8bea-a5d03a4d918c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Keras model...\n",
            "Epoch 1/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.1576 - loss: 0.0914 - val_accuracy: 0.1682 - val_loss: 0.0891\n",
            "Epoch 2/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.2775 - loss: 0.0888 - val_accuracy: 0.1982 - val_loss: 0.0881\n",
            "Epoch 3/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.2949 - loss: 0.0877 - val_accuracy: 0.3333 - val_loss: 0.0869\n",
            "Epoch 4/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.3523 - loss: 0.0865 - val_accuracy: 0.2584 - val_loss: 0.0854\n",
            "Epoch 5/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3272 - loss: 0.0848 - val_accuracy: 0.3508 - val_loss: 0.0832\n",
            "Epoch 6/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.3516 - loss: 0.0824 - val_accuracy: 0.4133 - val_loss: 0.0803\n",
            "Epoch 7/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.4026 - loss: 0.0793 - val_accuracy: 0.4292 - val_loss: 0.0767\n",
            "Epoch 8/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.4577 - loss: 0.0754 - val_accuracy: 0.4827 - val_loss: 0.0726\n",
            "Epoch 9/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5006 - loss: 0.0713 - val_accuracy: 0.5310 - val_loss: 0.0681\n",
            "Epoch 10/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5461 - loss: 0.0666 - val_accuracy: 0.6078 - val_loss: 0.0633\n",
            "Epoch 11/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.6059 - loss: 0.0618 - val_accuracy: 0.6414 - val_loss: 0.0584\n",
            "Epoch 12/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.6531 - loss: 0.0573 - val_accuracy: 0.6937 - val_loss: 0.0537\n",
            "Epoch 13/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6951 - loss: 0.0524 - val_accuracy: 0.7100 - val_loss: 0.0495\n",
            "Epoch 14/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.7183 - loss: 0.0484 - val_accuracy: 0.7439 - val_loss: 0.0455\n",
            "Epoch 15/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.7495 - loss: 0.0444 - val_accuracy: 0.7729 - val_loss: 0.0420\n",
            "Epoch 16/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.7837 - loss: 0.0410 - val_accuracy: 0.8008 - val_loss: 0.0387\n",
            "Epoch 17/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8033 - loss: 0.0380 - val_accuracy: 0.8173 - val_loss: 0.0359\n",
            "Epoch 18/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.8257 - loss: 0.0350 - val_accuracy: 0.8339 - val_loss: 0.0333\n",
            "Epoch 19/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8399 - loss: 0.0326 - val_accuracy: 0.8437 - val_loss: 0.0311\n",
            "Epoch 20/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.8495 - loss: 0.0301 - val_accuracy: 0.8535 - val_loss: 0.0292\n",
            "Epoch 21/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8525 - loss: 0.0286 - val_accuracy: 0.8559 - val_loss: 0.0277\n",
            "Epoch 22/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8604 - loss: 0.0269 - val_accuracy: 0.8624 - val_loss: 0.0262\n",
            "Epoch 23/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8659 - loss: 0.0255 - val_accuracy: 0.8655 - val_loss: 0.0250\n",
            "Epoch 24/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8685 - loss: 0.0245 - val_accuracy: 0.8696 - val_loss: 0.0240\n",
            "Epoch 25/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.8729 - loss: 0.0233 - val_accuracy: 0.8722 - val_loss: 0.0231\n",
            "Epoch 26/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8743 - loss: 0.0226 - val_accuracy: 0.8741 - val_loss: 0.0224\n",
            "Epoch 27/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8771 - loss: 0.0218 - val_accuracy: 0.8755 - val_loss: 0.0217\n",
            "Epoch 28/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8793 - loss: 0.0211 - val_accuracy: 0.8784 - val_loss: 0.0212\n",
            "Epoch 29/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.8817 - loss: 0.0206 - val_accuracy: 0.8794 - val_loss: 0.0207\n",
            "Epoch 30/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8827 - loss: 0.0200 - val_accuracy: 0.8818 - val_loss: 0.0201\n",
            "Epoch 31/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8843 - loss: 0.0196 - val_accuracy: 0.8835 - val_loss: 0.0197\n",
            "Epoch 32/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8872 - loss: 0.0192 - val_accuracy: 0.8855 - val_loss: 0.0193\n",
            "Epoch 33/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8846 - loss: 0.0192 - val_accuracy: 0.8886 - val_loss: 0.0189\n",
            "Epoch 34/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8916 - loss: 0.0183 - val_accuracy: 0.8880 - val_loss: 0.0186\n",
            "Epoch 35/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8937 - loss: 0.0178 - val_accuracy: 0.8890 - val_loss: 0.0184\n",
            "Epoch 36/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8919 - loss: 0.0177 - val_accuracy: 0.8898 - val_loss: 0.0181\n",
            "Epoch 37/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8918 - loss: 0.0177 - val_accuracy: 0.8900 - val_loss: 0.0178\n",
            "Epoch 38/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8984 - loss: 0.0171 - val_accuracy: 0.8910 - val_loss: 0.0176\n",
            "Epoch 39/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.8956 - loss: 0.0171 - val_accuracy: 0.8920 - val_loss: 0.0174\n",
            "Epoch 40/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8983 - loss: 0.0168 - val_accuracy: 0.8951 - val_loss: 0.0172\n",
            "Epoch 41/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8986 - loss: 0.0166 - val_accuracy: 0.8939 - val_loss: 0.0170\n",
            "Epoch 42/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.8965 - loss: 0.0166 - val_accuracy: 0.8933 - val_loss: 0.0168\n",
            "Epoch 43/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8972 - loss: 0.0164 - val_accuracy: 0.8949 - val_loss: 0.0167\n",
            "Epoch 44/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9017 - loss: 0.0159 - val_accuracy: 0.8957 - val_loss: 0.0165\n",
            "Epoch 45/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9002 - loss: 0.0160 - val_accuracy: 0.8961 - val_loss: 0.0164\n",
            "Epoch 46/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9010 - loss: 0.0158 - val_accuracy: 0.8957 - val_loss: 0.0162\n",
            "Epoch 47/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9007 - loss: 0.0158 - val_accuracy: 0.8980 - val_loss: 0.0161\n",
            "Epoch 48/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9012 - loss: 0.0157 - val_accuracy: 0.8978 - val_loss: 0.0160\n",
            "Epoch 49/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9044 - loss: 0.0153 - val_accuracy: 0.8996 - val_loss: 0.0158\n",
            "Epoch 50/50\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9050 - loss: 0.0152 - val_accuracy: 0.8992 - val_loss: 0.0157\n"
          ]
        }
      ],
      "source": [
        "# 5. Train\n",
        "print(\"Training Keras model...\")\n",
        "history = model.fit(X_train, y_train_onehot,\n",
        "                    epochs=50,\n",
        "                    batch_size=100,\n",
        "                    validation_split=0.1,\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu_n-iYmFbha",
        "outputId": "9dc0601b-6ac0-49c9-854c-11e1ff2d8cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating performance...\n",
            "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "Test Accuracy: 90.17%\n",
            "Macro AUC: 98.99\n"
          ]
        }
      ],
      "source": [
        "# 6. Evaluate\n",
        "print(\"\\nEvaluating performance...\")\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred_class = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred_class)\n",
        "macro_auc = roc_auc_score(y_test_onehot, y_pred_proba, average='macro', multi_class='ovr')\n",
        "\n",
        "print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
        "print(f\"Macro AUC: {macro_auc*100:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}